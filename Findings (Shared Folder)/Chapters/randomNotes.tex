
\chapter{Some Notes on Mathematical Modeling}
These are the steps for mathematical modeling that I have gathered by thinking deep and observing what is happening around me. How my supervisors attack a problem, what is the thought process of professor X in dealing with a problem at one glance, what are the concerns about a specific type of problem (like Stock's problem in PDE theory which is a saddle-node type problem), and what are the main tools to address that problem. These steps in modeling a phenomena mathematically gives me a sense of orientation in a busy world full of new things. This section will be developed overtime, and at some point it can be a chapter of my thesis.

\begin{summary}
	The primary purpose of these notes is to locate the stage of any ongoing project. Also, I will do my best to prepare a kind of checklist for each step that can be used to evaluate the progress of the sub-steps of the project.
\end{summary}

\section{STEP 0: Understanding the phenomena we want to study}

\section{STEP I: Converting Natural Phenomena to a Mathematical Problem }
This step is one of the steps that looks very strange for me. Early from calculus courses and elementary ODE, PDE courses, we can see phrase like ``this Dirichlet boundary condition along with an elliptic PDE models a rod that its two ends are covered with ice at temperature 0'', or ``This saddle-point problem named Stokes problem models a non-compressible fluid''. But they never talk about why this is true, and even how this is possible? Why a bunch of numbers and functions should mimic a very complex phenomena?

There are some very interesting papers written to explain why the mathematics is so effective in modeling the natural world (see \autoref{fig:mathmodelingmatheffectiveness}). In my opinion, this step, although innocent looking, is a totally non-trivial step. Because the nature is what it is, and the fact that some abstract notions and objects can mimic those natural phenomena with nuance details (like the things that happens in bifurcation) is very strange. 

At this step, we need to first \textbf{identify the questions} that we want to answer. This is the most important step that affects all of the subsequence analysis. We need to ask ourselves \textbf{to what level of accuracy} we want our answer? \textbf{To what level of generality} we want our answer be?

This step is the step in which we make our decisions. We decide what details to include or ignore. We decide what are the concrete questions we want to answer. This will determine the right mathematical tools that we can use. 

\begin{summary}[Step I: Converting a natural phenomena to a mathematical problem]
	$ \; $
	\begin{enumerate}[(i)]
		\item The most important thing: What is the question that we want to answer?
		\item We make lots of decisions:
		\begin{itemize}
			\item What is the precision in the answer that we are looking for?
			\item What is the generality that we are after?
			\item What is an appropriate mathematical tool that can be used to model?
		\end{itemize}
		
	\end{enumerate}
\end{summary}

\begin{figure}
	\centering
	\captionsetup{width=.9\linewidth}
	\includegraphics[width=1\linewidth]{images/EffectinvenessOFMath.pdf}
	\caption{A series of papers written after Wigner's famous article published in 1960 \cite{Wigner1995}. Several famous scientists of the time responded to this paper, by expanding the ideas to particular fields, among which are \cite{Hamming1980},  \cite{Lesk2000},  \cite{Tegmark2008}, and \cite{GrattanGuinness2008}. }
	\label{fig:mathmodelingmatheffectiveness}
\end{figure}

\FloatBarrier

\section{STEP II: Mathematical Analysis of the Model in Hand}
After doing the STEP I appropriately, we will have a mathematical description of the phenomena in our hand. This mathematical formulation on the problem can come in my different flavors and forms, We can categorize them by considering their different aspects, like being a discrete or continuous model, being a deterministic or stochastic model, etc. Each of these formulations will have its own appropriate way of treating. So I will discuss their subsequence steps separately.
 
 
\subsection{STEP II: PDE models}
After converting the natural phenomena to a mathematical model containing PDEs, we will have a domain, and a PDE. For instance, let $ \Omega \subset \R^2 $, and we define
\begin{align*}
	-\Delta u  &= g, \qquad \text{on }\Omega, \\
	u &= 0, \qquad \text{on } \partial \Omega.
\end{align*}
In this particular problem, we have a domain, on which we are interested in finding a mapping $ u:\Omega \to \R $ whose partial derivatives satisfies a certain equation. Our first goal is to determine if this problem has a solution (existence), and then to see if the problem as a unique solution (uniqueness), and then to see if the solution is stable (i.e. bounded by the given data). 

\begin{summary}
	Given a PDE in hand, it is important to see if the problem is well-posed (in the sense  of Hadamard). I.e.
	\begin{itemize}[noitemsep]
		\item a solution exists,
		\item the solution is unique, and
		\item the solution is stable.
		
	\end{itemize}
\end{summary}

\subsubsection{Different Formulations of the Problem: Strong vs. Weak Formulation}
To find the answers to these questions, we can formulate our problem in different ways, i.e. strong formulation, or a weak formulation. In the weak formation, we have more relaxed requirements on the solutions. For instance, for a classic solution to satisfy an elliptic Dirichlet boundary value problem, by definition, it needs to have two derivatives while being zero at the boundary (i.e. $ u \in C_c^2(\Omega) $). However, we can relax this requirement by a kind of axiomatic extension of the set of possible solutions. For instance, we know that all $ C_c^2(\Omega) $ functions has a nice interaction with $ C_c^\infty(\Omega) $ functions through the integration by parts formula.
\[ \int_\Omega \nabla u \nabla v = -\int_\Omega u \nabla v \qquad \forall v \in C_c^\infty (\Omega).  \]
Thus we can use this property as a definition of derivative, and define the notion of the weak derivative. We can use this property to formulate the problem in weak sense. 
\[ \int_\Omega \nabla u \ \nabla v = \int_\Omega g v \qquad \forall v \in H_0^1(\Omega). \]
We can now write the problem in a more abstract form by defining bi-linear forms
\[ a: H_0^1 \times H_0^1 \to \R, \qquad l:H_0^1 \to \R \] 
and define 
\[ a(u,v) = \int_\Omega \nabla u\  \nabla v, \qquad l(v) = \int_\Omega gv. \]
Thus we can now write the weak formulation as the following abstract equation, i.e. we say $ u $ satisfies the boundary value problem stated above if it satisfies
\begin{align*}
	&a(u,v)  = l(v), \qquad \forall v \in H_0^1,\\
	&u = 0 \quad \text{on}\ \partial \Omega.
\end{align*}

\subsubsection{well-Posedness}
Writing the problem in hand in abstract form, helps us to use other existing mathematical infrastructure to understand if a solution exists, if it is unique, and if it is stable. For instance, writing the elliptic problem in the form of $ a(u,v) = l(v) $ allows us to use the infrastructure developed in functional analysis to find the answers to our questions. For instance, in this particular case, we can use the Lax-Milgram theorem (which is a kind of generalization to the Ritz-representation theorem) to show that under certain conditions (i.e. the bi-linear form $ a $ being coercive and bounded, and the linear form $ l $ being bounded. ) a solution exists, and is unique and stable (i.e. bounded by the data). Or in the case of the Stokes problem for the non-compressible fluid, we have the  Ladyzhenskaya-Babuška-Brezzi condition (or LBB in short) which is also often called inf-sup condition, is a set of conditions under which the Stokes problem as a unique solution that is stable. 

\begin{summary}[Importance of formulating the mathematical problem appropriately]
	Formulating a mathematical problem in an appropriate way is very crucial. Appropriate formulations allows us to use the existing important theorems in a specific field of mathematics to our advantage. For instance, by formulating a PDE in weak form and using suitable forms, we can use
	\begin{itemize}
		\item Lax-Milgram theorem (generalized form of Ritz-representation theorem) to show the well-posedness of an elliptic problem under certain conditions.
		\item Ladyzhenskaya-Babuška-Brezzi theorem (or LBB in short) to show the well-posedness of the Stokes problem for non compressible fluid.
	\end{itemize}
\end{summary}


\subsubsection{What kind of solutions do we need?}
The well-posedness of a problem is a hunting license to find the actual solutions. Again, we need to revisits our main question in step I. What are we looking for? Is having a solutions in closed form necessary? Can having the solution in a series form (with a high or low convergence rate) enough? Can we get the answers to our question by some sort of qualitative analysis? Is a numerical solution necessary? \textbf{The exact answer to these questions depends on the questions that we want to answer with mathematical modeling.}

\begin{summary}[Solutions to the PDE]
	After getting the hunting license and being sure about the well-posedness of the problem, we need to revisit our original question to decide what we want to do with the solution? The solution can be found in many ways that might be suitable for some cases and and overkill for other cases.
	\begin{itemize}
		\item closed form solution
		\item series solution (with poor or good convergence rate)
		\item some contracting map 
		\item local solution (for local behaviour analysis)
		\item numerical solution
		\item etc.
	\end{itemize}
\end{summary}

\subsubsection{Numerical Solution}
After deciding on if we need a numerical solution, we can use different approaches, each of which has its own treatment. Here I will only talk about the finite element methods. In the finite element method, we find a suitable finite dimensional sub-space of the solution space ($ H_0^1 $ in the case of the elliptic Dirichlet problem) and formulate the problem in discrete form. For instance, if we can generate a triangulation of a domain $ \Omega $ and define some local basis functions e.g. some continouse and piece-wise affine functions that each of them is non-zero only at one node. Thus we can express our function in the weak formulation in this form
\[ u = \sum_{i=1}^{n}U_i \phi_i(x), \qquad g = \sum_{i=1}^{n}G_i \phi_i(x). \]
By substituting this in the weak formulation, we will get the following system of linear equations
\[ A U = G, \]
where the matrix $ A $ (stiffness matrix) and the vector $  G $ are the given data and we want to find the vector $ U $. Or in the case of the Stokes problem, we will get the following system of equations.
\begin{align*}
	&AU + BP = F, \\
	&B^T U = 0.
\end{align*}
\textbf{Note}: After projecting the problem to a finite dimensional sub-space, it is not necessarily true the the well-posedness of the problem in the infinite dimensional Hilbert space carries over to the finite dimensional sub-space. For instance, in the case of the Stokes problem, the well-posedness does not carry over and we need to study the well-posedness of the discrete problem.

\subsubsection{Error Estimate}
Projecting an infinite dimensional space to a finite dimensional space introduces some errors that we need to be sure we can quantify and understand how does that error scales with the mesh size (i.e. the dimension of the finite dimensional sub-space).



\section{What Is the Flux, Really?}
Here in this section we will go deeper into the notion of flux in particle transport which is the central part mathematical modeling of living systems. I will try to connect this notion with mathematical objects with clear definitions rather than providing vague intuition.

Generally speaking, flux is a surface integral of some vector field, and by designing that vector field accurately, we can use the notion of flux in different contexts. Here we will design the notion of flux to study particles and their densities assuming they are non-compressible fluids. Let $ \Omega \subset \R^3 $. Define 
\[ J = \rho v \]
where
\[ \rho: \Omega\times \R \to \R, \qquad v:\Omega\times \R\to\R^3, \]
representing the density and the velocity of the scalar field respectively. But what is the velocity of $ \rho $? Here is the part where the notion of volume preserving diffeomorphisms become useful. Let $ X_0 \in\Omega $ denote the position of a point particle in the domain. Then its trajectory over time is determined by the action of the group $ \set{g^t}_{t \in T} $ on $ X_0 $. For instance $ X(t) = g^t X_0 $. Since we have assumed that the species are in form of non-compressible fluids, then the group $ \set{g^t} $ is a subgroup of the group of all diffeomorphisms that preserves the volume. For a fixed $ X_0 \in \Omega $ its orbit is defined to be
\[ \operatorname{Orbit}(X_0) = \set{g^t X_0 \ |\ t \in T}. \]
At any time $ t $, $ v(X,t) $ is defined to be
\[ v(X,t) = \lim_{\Delta t \to 0} \frac{g^{t+\Delta t} X - g^{t} X}{\Delta t} \]
This means that for $ X_0 \in A $ we can write
\[ g^{\Delta t} X_0 = X_0 + \vec{v}(X_0) \Delta t + O(\Delta t ^2) \]
which means that the effect of $ g^{\Delta t} $ on the point $ X_0 $ just shifting $ X_0 $ in the direction $ \vec{v}(X_0) \Delta t  $. In the figure below we can see this approximation on a particular orbit.
\input{images/orbitApproximation.tex}
Let $ \sigma $ be any surface given in the domain. We claim that the rate of volume passing through this membrane is given by
\[ \frac{dV}{dt} = \int_\sigma \vec{v}\cdot \hat{n}\ dA. \]
To see this $ \Delta A $ be the area of a flat square tangent to the membrane at point $ X_0 $ on the surface. See the figure below.
\input{images/rateOfVolumePass.tex}

\noindent We observe that the point $ X_0 $ moves to $ X_0 + \vec{v}(X_0)\Delta t + \O(\Delta t^2) $. Also, observe that the area any point on $ \Delta A $ distance $ \Delta r $ away from $ X_0 $ will be transferred to 
\[ g^{\Delta t} (X_0 + \Delta r) = X_0 + \Delta r + \vec{v}(X_0 + \Delta r)\Delta t + O(\Delta t^2) = (X_0 + \Delta r) + \vec{v}(X_0) \Delta t + O(\Delta t^2 + \Delta t \Delta r).  \]
Thus the area of the green surface in the figure above will be the same as $ \Delta A $ up to order
$ O((\Delta t^2 + \Delta t \Delta r)^2) $. Note that by the action of $ g^{\Delta t} $, everything in between the yellow and green surfaces will move through the green surface. So the volume that will pass through the green surface is
\[ \Delta V = (\vec{v}(X_0)\Delta t)\cdot \hat{n} \Delta A + O(\Delta t^2) \]
Given that the density of species is $ u $, then the number species passed through the green membrane after time $ \Delta t $ will be
\[ \frac{\Delta N}{\Delta t} = \vec{v}(X_0)\cdot \hat{n}\Delta A + O(\Delta t^2 + \Delta A^2) \]
I.e. we can write
\[ \frac{d N }{dt} = \int_\sigma \vec{v}\cdot \hat{n}\ dA \]


\begin{summary}
	\label{summary:groupActionOfDiffeomorphisms}
	In a nutshell, If we define 
	\[  J = \rho v \]
	where $ \rho :\Omega \times \R \to \R $ is a function representing the density, and $ v: \Omega \times \R \to \R^3 $ is the tangent vector to the orbit of particles generated by the action of group of diffeomorphisms that preserve the volume element $ \set{g^t}_{t\in T} $, then, for any surface $ \sigma \subset \Omega $, the rate of particles passing through the membrane will be
	\[ \frac{dN}{dt} = \int_\sigma J\cdot \hat{n}\ dA. \]
	Then by assuming that no particles will by destroyed to the thin air, and also no particles will born out of blue sky, then we can derive the continuity equation. In any volume $ V $ of our domain enclosed by the surface $ \sigma $, we can write
	\[ \frac{d}{dt} \int_V \rho\ dV = - \int_\sigma J\cdot \hat{n}\ dA = - \int_V \nabla\cdot J dV. \]
	By dropping the integration signs we will get
	\[ \frac{d\rho}{dt} + \nabla\cdot J = 0.  \]
\end{summary}


\begin{observation}
	Reading the summary box above, one might conclude that the flux for diffusion might be something like $ J = - \rho \nabla\rho $ as the particles are moving opposite to their gradient. But this is wrong! In the case of diffusion, the velocity field is
	\[ v = -\frac{1}{\rho} \nabla \rho \]
	so the flux (Fick's law) will be of the form
	\[  J =  -\nabla\rho. \]
	At first, it was as very bizarre observation for me. I still do not understand how I can derive this velocity profile (i.e. flow velocity or simply flow).
\end{observation}

\section{Some cool PDE simulations}
Living in this level of abstraction, we can now do some stuff with PDEs that might look magic at the first glace. Here, I will show case some of these simulations. 

\subsection{Diffusion and Advection}

\begin{quote}
	{\color{red} Be aware of the context.} Note that in this section, when we talk about the vector field $ F $, we are actually talking about the vector field that determines the advection term of the flux. I.e. we assume $ F $ is
	\[ J_\text{advection} = \rho F\]
\end{quote}
To have diffusion and advection at the same time, we need to design the flow in a way that can produce this. The first term of will be for the diffusion, where according to the observation box above will be of the form
\[  J = - \nabla\rho + \underbrace{\cdots}_{\text{advection term}} \]
To design the advection term, we need to observe that the particles should move along side some vector field. So it will be of the form
\[ \boxed{J_\text{advection} = \rho F(X)}  \]
where $ F: \Omega\to \R^3 $ is the desired vector field. So the advection-diffusion PDE will be 
\[ \frac{\partial \rho}{\partial t} = \nabla\cdot (-\nabla\rho + \rho F). \]
Now we can come up with all sort of creative vector fields.
\subsubsection{Simple velocity field}
For instance, for the vector field $ F(x,y)=(-1,0) $, we will have
\[ \frac{\partial \rho}{\partial t} = \nabla^2 \rho - \frac{\partial \rho}{\partial x}.  \]
Then the solution of this model will be like the following figure.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{images/simpleAdvectionDiffusion1}
	\caption{Advection diffusion with the vector field $ F(x,y,z) = (-1,0,0). $ The designed PDE forces the particles to move in this velocity field (or velocity profile).}
	\label{fig:simpleadvectiondiffusion1}
\end{figure}

\subsubsection{Particles Moving Down the Hill}
Here, we design a vector field that resembles particles moving down a potential hill to get to their minimum potential state. To design such a vector field, we simply first define an appropriate potential function and define the vector field to be its gradient. The potential that we will using for this purpose is 
\[ f(x,y) = 1/2(x^2 + y^2). \]
Then the corresponding vector field will be
\[ F(x,y) = -\nabla f(x,y) = (x,y). \]
So the desired PDE will be
\[ \frac{\partial \rho}{\partial t} = \nabla^2 \rho + x \frac{\partial \rho}{\partial x} + y \frac{\partial \rho}{\partial y} + \rho. \] 
Simulating this PDE we will get
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{images/movingToCenter.png}
	\caption{Advection diffusion with the vector field $ F(x,y) = (x,y)$ which is the gradient of potential function $ f(x,y) = 1/2(x^2 + y^2) $.}
	\label{fig:potentialAsGradient}
\end{figure}

\subsubsection{Moving Around the Origin}
What if at each point, we rotate the vector vector of the previous example by 90 degrees so that the particles will move around the origin. The vector field in previous example was $ F(x,y) = (x,y) $. To do the rotation we need ot multiply that in the rotation matrix
\[ F_\text{new}(x,y)=  \matt{0}{-1}{1}{0}F(x,y) = \vectt{-y}{x}.  \]
Thus the desired PDE will be
\[ \frac{\partial \rho}{\partial t} = \nabla^2 \rho - y\frac{\partial \rho}{\partial x} + x \frac{\partial \rho}{\partial y}. \]
By simulating this PDE we will get
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{images/movingAround.png}
	\caption{Advection diffusion with the vector field $ F(x,y,z) = (-y,x)$. This vector field is derived by rotating the vectors in the previous example by 90 degrees. Surprisingly, there are no potentials that $ F $ ce be its gradient! In other words, we can not derive $ F $ from any potential.}
	\label{fig:simpleadvectiondiffusion1}
\end{figure}

\FloatBarrier

\subsubsection{Spiraling in to the Origin}
We can start with the vector field $ F(x,y) = (x,y) $ and this time, rather time rotating it with a rotation matrix, we can rotate that using a matrix corresponding to a complex number $ z = \mu + i \omega $, i.e.
\[ F_\text{new}(x,y) = \matt{\mu}{-\omega}{\omega}{\mu}F(x,y). \]
We can take this complex number to be $ z = -1 + i $. Thus our new vector field will be
\[ F_\text{new}(x,y) = (-x+y, -x-y).  \]
So our PDE will read
\[ \frac{\partial \rho}{\partial t} = \nabla^2 \rho + (-x+y)\frac{\partial \rho}{\partial x} + (-x-y)\frac{\partial \rho}{\partial y} - 2\rho. \]
Simulating this PDE we will get

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{images/spiralAdvectionDiffusion.png}
	\caption{Advection diffusion with the vector field $ F_{\text{advection}}(x,y,z) = (-x+y, -x-y)$.}
	\label{fig:spiralAdvectionDiffusion}
\end{figure}
\FloatBarrier

Now the interesting question is why do we see this? To observe this, remember that the velocity profile is the same as the vector field that we specify for the model (in this case $ F_\text{new}(x,y) $). On the other hand, we know that the velocity profile is in fact the right hand side of the ODE for flow
\[ \frac{d \phi}{d t} = F_\text{new}(x,y). \]
Note that $ \phi $ is flow, or following the terminology of \autoref{summary:groupActionOfDiffeomorphisms}, it is one element of the group diffeomorphisms that preserve the volume element (in the that terminology we denote it by $ g^t $). For the simulation above, ODE for $ \phi:\R^2 \to \R^2 $ is 
\[ \vectt{\dot{\phi_1}}{\dot{\phi_2}} = \matt{-1}{1}{-1}{-1}\vectt{x}{y}. \]
The phase plane of flow will be

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.2\linewidth]{images/flowLinePlot.png}
	\caption{The phase plane of flow $ \phi_\text{advection} = (\phi_1,\phi_2) $}
	\label{fig:SpiralAdvectionDiffusionFlowPhasePortrait}
\end{figure}
\FloatBarrier
 
The following summary box summarizes our observation.
 
\begin{summary}[Advection-Diffusion PDE]
	In an advection diffusion PDE for $ \rho $ the flux will have two terms, 
	\[ J = \underbrace{-D\nabla \rho}_{J_\text{diffusion} = \rho v_\text{diffusion}}+ \underbrace{\rho F}_{J_\text{advection} = \rho v_\text{advection}} \]
	where $ F $ is a vector field, which is the velocity profile of advection (i.e. $ v_\text{advection} = F $). Thus the flow (or in the terminology of \autoref{summary:groupActionOfDiffeomorphisms} the diffeomorphism preserving the volume element) will be given with the following ODE
	\[ \frac{d \phi_\text{advection}}{dt} = v_\text{advection}. \]
	In the cases where we have small diffusion, the solution of the advection-diffusion PDE will look like the phase plane diagram of $ \phi_\text{advection} $. Compare \autoref{fig:spiralAdvectionDiffusion} with  \autoref{fig:SpiralAdvectionDiffusionFlowPhasePortrait} to see this.
\end{summary}


\begin{observation}
	Given what we discussed above, I have the following idea to study the phase plane of an ODE system in a wise way! Consider the following ODE system
	\[ \dot{\Phi} = F(\Phi). \]
	In the corresponding phase space diagram, we usually plot the vector field $ F(X) $ and roughly draw some important orbits (see \autoref{fig:SpiralAdvectionDiffusionFlowPhasePortrait}). However, using the machinery we discussed in the summary box above, we can also evaluate what will happen for a given volume of initial positions (i.e. a volume of phase space). We can design a PDE whose flow is given by $ \Phi $. Thus this PDE will be
	\[ \frac{\partial \rho}{\partial t} = -\nabla\cdot(\rho F(\Phi)), \]
	where $ \rho $ represents the density of states in the phase space. Note that the equation above is nothing more that just inserting an appropriate choice of flux into the continuity equation.
\end{observation}

\begin{observation}[A proof for Liouville's theorem (Hamiltonian)]
	After doing some research, I found out that the approach I have had in the observation above can be used to prove the Liouville's theorem for Hamiltonian. This was an independent discovery and proof of this theorem! 
	
	\begin{proof}
		consider the following Hamiltonian system
		\[ \Phi = \vectt{\dot{q}}{\dot{p}} = \vectt{\partial H/ \partial p}{- \partial H / \partial q} = F(\Phi). \]
		Let $ \rho $ be the density of states in the phase plane, since all of these points are following the flow profile, thus the corresponding flux will be
		\[  J = \rho \Phi.  \]
		Inserting this into the continuity equation we will get
		\[ \frac{\partial \rho}{\partial t} = -\nabla\cdot (\rho \Phi) = - \nabla \rho \cdot \Phi - \rho\nabla\cdot\Phi . \]
		For the first term in the right hand side we have
		\[ \nabla\rho\cdot \phi = \frac{\partial \rho}{\partial q}\cdot{q} + \frac{\partial \rho}{\partial p} \cdot{p}. \]
		And for the second term we can write
		\[ \rho\nabla\cdot\Phi = \rho(\frac{\partial^2 H}{\partial q\partial p} - \frac{\partial^2 H}{\partial p \partial q}) = 0. \]
		Thus we can write
		\[ \frac{\partial\rho}{\partial t} + (\frac{\partial \rho}{\partial q}\cdot{q} + \frac{\partial \rho}{\partial p} \cdot{p}) = 0.  \]
		This completes the proof.
	\end{proof}
\end{observation}

\begin{observation}
	The time evolution of the density of a die in an \emph{incompressible fluid} due to \emph{advection}, i.e. with the flux given by
	\[  J=\rho v\]
	 is analogous to the time evolution of the density of states in the phase plane of its flow $ \Phi $ (determined by the equation $ \dot{\Phi}=v $).
\end{observation}

In the observation box above, we have only talked about the rationale behind the PDEs that contains only the advection term. But what about the diffusion term? What are the ODE systems where the density of states in its phase plane will have a diffusion like behaviour? The following important observation box answers this important question.

\begin{observation}[Diffusion of the density of states in phase space]
	The statement of the question is as follows.
	\begin{quote}
		I was studying the PDEs governing the time evolution of the concentration of some die in an incompressible fluid. I noticed this general framework behind that which can be applied to the time evolution of the density of states in the phase plane of an ODE system. Once we know the governing ODE for the state of a system, lets say
		\[ \dot{X}  = F(X) \] 
		Then we can draw the phase plane with some important orbits in it. However, in order to find out what is the time evolution of the density of states, then we can easily find a corresponding PDE given by first defining $  J = \rho F$ and then writing
		\[ \rho_t = -\nabla\cdot(\rho F) = -\nabla\cdot(J). \]
		This gives the time evolution of a given density of states. In order to have a diffusion like behaviour in the phase plane, we should have $  J = \rho F = -\nabla \rho$. This means that the corresponding RHS for ODE should be $ F = -1/\rho \nabla \rho $ which does not make sense for me, as when writing the ODE for $ X $ the right hand side depends on the density of the states which does not makes sense in an ODE. So my question is that in what situation the density of states in and ODE system will have a diffusion like behaviour?
	\end{quote}
	
	The answer to this question has very deep roots in the stochastic vs. deterministic systems. The fact is that in \emph{deterministic} ODEs, we will \emph{never} observe a \emph{diffusion like behaviour} in the density of states of phase plane. The diffusion like behaviour of the density of states happens only in the case of Stochastic Differential Equations (SDE). As in the case of deterministic ODE systems, defining a suitable flux and inserting it into the continuity equation gives us the PDE for the time evolution of the density of states, doing a similar process gives us the Fokker-Plank equation that describes the time evolution of the density of states (which is called probability density function in this context) of the corresponding SDE. Consider the following SDE
	\[ dX_t = \mu(X_t,t)dt + \sigma(X_t,t)dW_t, \]
	where $ \mu(X_t,t) $ is the drift and $ D(X_t,t) = \sigma^2(X_t,t)/2 $ is the diffusion coefficient. The corresponding Fokker-Plank equation for the probability density function $ p(x,t) $ of the random variable $ X_t $ (analogous to the notion of the density of states in what we had discussed above) is given by
	\[ \frac{\partial}{\partial t} p(x,t) = -\frac{\partial}{\partial x}[\mu(x,t)p(x,t) - \frac{\partial}{\partial x}(D(x,t)p)]. \]
	Similarly, for the higher dimensions, the SDE will be of the form
	\[ d\mathbf{X_t} = \boldsymbol{\mu}(\mathbf{X_t},t)dt + \boldsymbol{\sigma}(\mathbf{X_t},t)d\mathbf{W_t}, \]
	where $ \mathbf{X_t} $ and $ \boldsymbol{\mu} $ are $ N $ dimensional vectors, and $ \boldsymbol{\sigma} $ is $ N\times M $ matrix, and $ \mathbf{W_t} $ is an $ M $ dimensional Wiener process. Then the corresponding Fokker-Plank equation will be given as
	\[ \frac{\partial p}{\partial t} = -\nabla\cdot(p\boldsymbol{\mu} + \boldsymbol{\nabla}\cdot(p\mathbf{D})) \]
	where the bold letter $ \boldsymbol{\nabla}\cdot$  applied on a matrix outputs a vector where each row is the divergence of the rows of the input matrix, and the matrix $ \mathbf{D} = \frac{1}{2}\boldsymbol{\sigma}\boldsymbol{\sigma^T} $. See examples below for more details.
\end{observation}

\begin{example}[1D Diffusion Equation]
	Consider the following SDE
	\[ dX_t = \sqrt{D}dW_t. \]
	The PDE governing the density of states (or the probability density function), i.e. the Fokker-Plank equation is given by
	\[ \frac{\partial p}{\partial t} = -\frac{\partial}{\partial x} (-D \frac{\partial p}{\partial x}) = D\frac{\partial ^2 p}{\partial x^2}, \]
	which gives rise to the 1D diffusion equation.
\end{example}

\begin{example}[2D Diffusion Equation]
	Consider the following system of SDEs
	\[ \vectt{dX_t}{dY_t} = \matt{1}{0}{0}{1}\vectt{dW^{[1]}_t}{dW^{[2]}_t}. \]
	The corresponding Fokker-Plank equation will be
	\[ \frac{\partial p}{\partial x} = \nabla\cdot(\boldsymbol{\nabla}\cdot\matt{p}{0}{0}{p}) 
	= \nabla\cdot(\vectt{p_x}{p_y}) = p_{xx} + p_{yy},
	 \]
	Which is the 2D diffusion equation.
\end{example}

\begin{example}[Advection Diffusion Equation]
	For instance, if we have
	\[ \vectt{dX_t}{dY_t} = \mathbf{F}(X_t)dt +  \matt{1}{0}{0}{1}\vectt{dW^{[1]}_t}{dW^{[2]}_t}. \]
	Then the corresponding Fokker-Plank equation will be
	\[ \frac{\partial p}{\partial t} = -\nabla\cdot( -\boldsymbol{\nabla}\cdot(\matt{p}{0}{0}{p}) + p\mathbf{F}) = -\nabla\cdot(-\nabla p + p\mathbf{F}). \]
	which is nothing but the familiar advection-diffusion system. Note that first term inside the parenthesis is the Fick's first law and the second term is taking care of the fact that the particles are advecting according to the vector field $ \mathbf{F} $.
\end{example}

\begin{example}[Boltzmann Distribution at the Thermodynamic Equilibrium]
	Consider the following SDE that is the overdamped Langevin equation
	\[ dX_t = -\frac{1}{k_BT}(\nabla U) dt + dW_t. \]
	Observe that similar to the example corresponding to \autoref{fig:potentialAsGradient} we defined the vector field for advection (drift) term as the gradient of a potential function. Thus similar to the example mentioned above, the particles will following trajectories down the potential well. The corresponding Fokker-Plank equation will be
	\[ \frac{\partial p}{\partial t} = -\frac{\partial}{\partial x}(-\frac{\partial p}{\partial x} - p\frac{1}{k_BT}\nabla U ), \]
	where we have kept writing the derivative of $ U $ as $ \nabla U $ to emphasis it is the gradient of a potential, but in fact we have $ \nabla U = \frac{\partial U}{\partial x} $. The steady state solution for the PDE above is
	\[ \frac{d p}{d x} = \frac{-p}{k_BT}\frac{d U}{d x}. \]
	The solution of the ODE above is given by
	\[\boxed{ p(x) = A e^{-\frac{U(x)}{k_BT}}}. \]
\end{example}

\begin{example}[Ornstein-Uhlenbeck process]
	Consider the following SDE
	\[ dX_t = -X_tdt + dW_t. \]
	Then the corresponding Fokker-Plank equation will be
	\[ \frac{\partial p}{\partial t} = -\frac{\partial}{\partial x}(-px - p_x). \]
	The steady state solution of this PDE will be given as
	\[ \frac{d p}{dx}  = - p x + c.\]
	The solution of this differential equation is given as
	\[ \boxed{p(x) = A e^{-x^2/2}}. \]
	This model is used to model the financial markets.
\end{example}


